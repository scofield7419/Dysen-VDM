<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models">
    <meta name="keywords" content="text-to-video generation, Large Language Models, video synthesis">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Dysen-VDM</title>

    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">
    <link rel="icon" href="./static/images/video.png">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>

    <style>
    .my-margin{
        margin-left: 9pt;
        width:24%;
        float:left;
    }
    </style>
</head>
<body>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Dysen-VDM:</h1>
                    <h1 class="title is-2 publication-title">Empowering Dynamics-aware Text-to-Video</h1>
                    <h1 class="title is-2 publication-title" style="margin-top: -17px;">Diffusion with Large Language
                        Models</h1>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://haofei.vip/">Hao Fei</a><sup>1</sup>,
            </span>
                        <span class="author-block">
              <a href="https://chocowu.github.io/">Shengqiong Wu</a><sup>1</sup>,
            </span>
                        <span class="author-block">
              <a href="https://jiwei0523.github.io/">Wei Ji</a><sup>1</sup>,
            </span>
                        <span class="author-block">
              <a href="https://mreallab.github.io/people.html">Hanwang Zhang</a><sup>2</sup>,
            </span>
                        <span class="author-block">
              <a href="https://chuatatseng.com/">Tat-Seng Chua</a><sup>1</sup>
            </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b>1. National University of Singapore</span>
                        <br>
                        <span class="author-block"><b style="color:#00A4EF; font-weight:normal">&#x25B6 </b>2. Nanyang Technological University</span>

                    </div>

                    <!-- <div class="is-size-5 publication-authors">
                      <span class="author-block" style="font-size: 15px;"><sup>*</sup>Equal Contribution</span> &nbsp; &nbsp; &nbsp; &nbsp;
                      <span class="author-block" style="font-size: 15px;"><sup>#</sup>Correspondence</span>

                    </div> -->

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
                <a href="https://arxiv.org/pdf/xxxx.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

                            <span class="link-block">
                <a href="https://huggingface.co/spaces/xxxx/Dysen-VDM" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-laugh"></i>
                  </span>
                  <span>Demo</span>
                </a>
              </span>

                            <!-- Video Link. -->
                            <!-- <span class="link-block">
                              <a href="https://www.youtube.com"
                                 class="external-link button is-normal is-rounded is-dark">
                                <span class="icon">
                                    <i class="fab fa-youtube"></i>
                                </span>
                                <span>Video</span>
                              </a>
                            </span> -->

                            <!-- Code Link. -->
                            <span class="link-block">
                <a href="https://github.com/scofield7419/Dysen"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>


                            <!-- <span class="link-block">
                              <a href="https://github.com/LayoutLLM-T2I/LayoutLLM-T2I" target="_blank"
                                 class="external-link button is-normal is-rounded is-dark">
                                <span class="icon">
                                  <i class="fa fa-database"></i>
                                </span>
                                <span>Dataset</span>
                                </a>
                            </span> -->


                            <!--               <span class="link-block">
                                            <a href="https://github.com/LayoutLLM-T2I/LayoutLLM-T2I"
                                               class="external-link button is-normal is-rounded is-dark">
                                              <span class="icon">
                                                  <i class="ai ai-arxiv"></i>
                                              </span>
                                              <span>arXiv</span>
                                            </a>
                                          </span> -->


                        </div>

                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="hero teaser">
    <div class="container is-max-desktop">
        <!--    <div class="hero-body">-->
        <!--      <h2 class="subtitle has-text-centered">-->
        <!--        LayoutLLM for image layout generation based on text inputs. -->
        <!--      </h2>-->
        <!--      <video id="teaser" autoplay muted loop playsinline height="200%">-->
        <!--        <source src="./static/videos/merged_images.mp4"-->
        <!--                type="video/mp4">-->
        <!--      </video>-->
        <!--    </div>-->

        <!--     <div class="hero-body">
              <h2 class="subtitle has-text-centered">
                LayoutGPT for 3D indoor scene synthesis.
              </h2>
              <video id="teaser" autoplay muted loop playsinline height="100%">
                <source src="./static/videos/merged_scenes.mp4"
                        type="video/mp4">
              </video>

            </div> -->

    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Text-to-video (T2V) synthesis has gained increasing attention in the community, in which the
                        recently emerged diffusion models (DMs) have promisingly shown stronger performance than the
                        past approaches.
                        While existing state-of-the-art (SoTA) DMs are competent to achieve high-resolution video
                        generation, they may largely suffer from key limitations (e.g., action occurrence disorders,
                        crude video motions) with respect to the <em>intricate temporal dynamics modeling</em>, one of
                        the crux of video synthesis.
                        In this work, we investigate strengthening the awareness of video dynamics for DMs, for
                        high-quality T2V generation.
                        Inspired by human intuition, we design an innovative dynamic scene manager (dubbed as <strong>Dysen</strong>)
                        module, which includes
                        (<strong>step-1</strong>) extracting from input text the key actions with proper time-order
                        arrangement,
                        (<strong>step-2</strong>) transforming the action schedules into the dynamic scene graph (DSG)
                        representations,
                        and (<strong>step-3</strong>) enriching the scenes in the DSG with sufficient and reasonable
                        details.
                        Taking advantage of the existing powerful LLMs (e.g., ChatGPT) via in-context learning, Dysen
                        realizes (nearly) human-level temporal dynamics understanding.
                        Finally, the resulting video DSG with rich action scene details is encoded as fine-grained spatio-temporal features, integrated into
                        the backbone T2V DM for video generating.
                        Experiments on popular T2V datasets suggest that our framework consistently outperforms prior
                        arts with significant margins, especially in the scenario with complex actions.
                    </p>

                </div>
            </div>
        </div>
        <!--/ Abstract. -->

        <!-- Paper video. -->
        <!-- <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
              <iframe src="https://www.youtube.com/"
                      frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div> -->
        <!--/ Paper video. -->
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">

        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Motivation</h2>

                <div class="content has-text-justified">
                    <p>
                    <figure style="float:right; clear:both; width:40%">
                        <img src="./static/images/intro3.png">
                        <figcaption>
                            <p style="text-align: justify;">
                                <font color="061E61">
                                    <b>Fig.1 :</b> Common issues in the existing text-to-video (T2V) synthesis.
                                </font>
                            </p>
                        </figcaption>
                    </figure>
                    Currently, DM-based T2V can still face several common yet non-negligible challenges.
                    As summarized in Fig. 1, four typical issues can be found in a diffusion-based T2V model, such as
                    <em><b>lower frame resolution</b></em>, <em><b>unsmooth video transition</b></em>, <em><b>crude
                    video motion</b></em> and <em><b>action occurrence disorder</b></em>.
                    While the latest DM-based T2V explorations paid much effort into enhancing the quality of video
                    frames, i.e., generating high-resolution images, they may largely overlook the modeling of the <b>intricate
                    video temporal dynamics</b>, the real crux of high-quality video synthesis, i.e., for relieving the
                    last three types of aforementioned issues.
                    According to our observation, the key bottleneck is rooted in the nature of video-text modality
                    heterogeneity:
                    language can describe complex actions with few succinct and abstract words (e.g., predicates and
                    modifiers),
                    whereas video, however, requires specific and often redundant frames to render the same actions.
                    </p>
                </div>
                <br/>

            </div>
        </div>

        <!-- Framework -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Framework</h2>

                <div class="content has-text-justified">
                    <p>
                        We propose a dynamics-aware T2V diffusion model, namely <b>Dysen-VDM</b>, as shown in Fig.2.
                        We first employ the existing SoTA latent DM for the backbone T2V synthesis, and meanwhile devise an innovative <u><b>dy</b></u>namic
                        <u><b>s</b></u>c<u><b>en</b></u>e manager (namely <b>Dysen</b>) module for video dynamics
                        modeling.
                    </p>
                    <figure>
                        <img class="columns is-centered has-text-centered" src="./static/images/framework.png"
                             alt="Teaser" width="100%" style="margin:0 auto">
                        <figcaption>
                            <p style="text-align: justify;">
                                <font color="061E61">
                                    <b>Fig.2 :</b> Our dynamics-aware T2V diffusion framework (<b>Dysen-VDM</b>). The
                                    dynamic scene manager (Dysen) module operates over the input text prompt and
                                    produces the enriched dynamic scene graph (DSG), which is encoded by the recurrent
                                    graph Transformer (RGTrm), and the resulting fine-grained spatio-temporal scene
                                    features are integrated into the video generation (denoising) process.
                                </font>
                            </p>
                        </figcaption>
                        <!--              Fig.1 - Our dynamics-aware T2V diffusion framework. The dynamic scene manager (Dysen) module operates over the input text prompt and produces the enriched dynamic scene graph (DSG), which is encoded by the recurrent graph Transformer (RGTrm), and the resulting fine-grained spatio-temporal scene features are integrated into the video generation (denoising) process.</figcaption>-->
                    </figure>
                    <p>
                        With Dysen, we realize the human-level temporal dynamics understanding of video. We take advantage of the
                        current most powerful LLM, ChatGPT; we treat ChatGPT as the consultant for action planning and
                        scene imagination in Dysen.
                    <ul>
                        <li>
                            <b>Step-I:</b> extracting the key actions from the input text, which are properly arranged
                            in occurring orders.
                        </li>
                        <li>
                            <b>Step-II: </b> converting these ordered actions into sequential dynamic scene graph (DSG)
                            representations.
                        </li>
                        <li>
                            <b>Step-III: </b> enriching the scenes in the initial DSG with sufficient and reasonable
                            details elicited from ChatGPT via in-context learning.
                            <!--                , in which we further design a <em>REINFORCE</em>-based algorithm to actively optimize the ChatGPT utility.-->
                        </li>
<!--                        <li>-->
<!--                            <b>Step-IV: </b> the resulting DSG with well-enriched scene details is encoded with a-->
<!--                            recurrent graph Transformer, where the learned delicate fine-grained spatio-temporal-->
<!--                            features are integrated into the backbone T2V DM for generating high-quality fluent video.-->
<!--                        </li>-->
                    </ul>
                    Finally, the resulting DSG with well-enriched scene details is encoded with a
                            recurrent graph Transformer, where the learned delicate fine-grained spatio-temporal
                            feature representations are integrated into the backbone T2V DM for generating high-quality fluent video.
                    </p>
                    <figure>
                        <img class="columns is-centered has-text-centered" src="./static/images/imagination.png"
                             alt="Teaser" width="100%" style="margin:0 auto">
                        <figcaption>
                            <p style="text-align: justify;">
                                <font color="061E61">
                                    <b>Fig.3 :</b> Based on the given text, Dysen module carries out three steps of
                                    operations to obtain the enriched DSG: 1) action planning, 2) event-to-DSG
                                    conversion, and 3) scene imagination, where we take advantage of the ChatGPT with
                                    in-context learning.
                                </font>
                            </p>
                        </figcaption>
                        <!--              Fig.2 -Based on the given text, Dysen module carries out three steps of operations to obtain the enriched DSG: 1) action planning, 2) event-to-DSG conversion, and 3) scene imagination, where we take advantage of the ChatGPT with in-context learning.</figcaption>-->

                    </figure>

                </div>
                <br/>

            </div>
        </div>


        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Demo Examples</h2>


                <h4 style="margin-top: 50px" class="title is-5">▶ High-quality demos (576 x 320)</h4>

                <figure style="display: flex;flex-direction: column;align-items: center;">
                    <img src="./static/images/high/hq-1.gif" alt="Teaser" style="width:70%">
                    <figcaption style="margin-bottom:15pt">
                        A lady holds umbrella, walking on the park with her friend.
                    </figcaption>
                </figure>

                <figure style="display: flex;flex-direction: column;align-items: center;">
                    <img src="./static/images/high/hq-2.gif" alt="Teaser" style="width:70%">
                    <figcaption style="margin-bottom:15pt">
                        A bustling morning of market with crowd.
                    </figcaption>
                </figure>

                <figure style="display: flex;flex-direction: column;align-items: center;">
                    <img src="./static/images/high/hq-3.gif" alt="Teaser" style="width:70%">
                    <figcaption style="margin-bottom:15pt">
                        In the kitchen, the women assists her dad cooked dinner by trimming the vegetables.
                    </figcaption>
                </figure>

                <figure style="display: flex;flex-direction: column;align-items: center;">
                    <img src="./static/images/high/hq-4.gif" alt="Teaser" style="width:70%">
                    <figcaption style="margin-bottom:15pt">
                        Friends dance to music in the party.
                    </figcaption>
                </figure>

                <figure style="display: flex;flex-direction: column;align-items: center;">
                    <img src="./static/images/high/hq-5.gif" alt="Teaser" style="width:70%">
                    <figcaption style="margin-bottom:15pt">
                        Students listen to the teacher in the classroom, with some raising hands.
                    </figcaption>
                </figure>

                <figure style="display: flex;flex-direction: column;align-items: center;">
                    <img src="./static/images/high/hq-6.gif" alt="Teaser" style="width:70%">
                    <figcaption style="margin-bottom:15pt">
                        In the gym, man and woman are running on treadmills.
                    </figcaption>
                </figure>

                <br/>


                <h4 style="margin-top: 50px" class="title is-5">▶ Comparisons between baselines (320 x 320)</h4>

                <!--        <h3 class="title is-4">Examples: Spatial, Semantic</h3>-->
                <div style="width:25%;float:left;margin-bottom: 8pt;font-weight: bold;    font-size: 16pt;">
                    <p style="text-align: center">CogVideo</p>
                </div>
                <div style="width:25%;float:left;margin-bottom: 8pt;font-weight: bold;    font-size: 16pt;">
                    <p style="text-align: center">VDM</p>
                </div>
                <div style="width:25%;float:left;margin-bottom: 8pt;font-weight: bold;    font-size: 16pt;">
                    <p style="text-align: center">LVDM</p>
                </div>
                <div style="width:25%;float:left;margin-bottom: 8pt;font-weight: bold;    font-size: 16pt;">
                    <p style="text-align: center">Dysen-VDM (Ours)</p>
                </div>
                <figure>
                    <img src="./static/images/low/group1/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group1/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group1/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group1/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A woman is looking after the plant in her garden, and then she raises her head to observe the weather.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group2/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group2/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group2/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group2/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A man with his dog walks on the countryside road.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group3/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group3/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group3/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group3/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A man dressed as Santa Claus is riding a motorcycle on a big city road.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group4/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group4/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group4/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group4/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A clownfish swimming with elegance through coral reefs, presenting
                        the beautiful scenery under the sea.
                    </figcaption>
                </figure>
                    <img src="./static/images/low/group5/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group5/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group5/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group5/ours.gif" alt="Teaser">
                <figcaption style="margin-bottom:15pt">
                    A cowboy who wears a cowboy hat, a t-shirt and a jeans is riding a horse to
                    confidently compete in a rodeo competition.
                </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group6/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group6/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group6/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group6/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A young violin player in a neat shirt with a collar, having a
                        headphone on, is playing the violin.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group7/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group7/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group7/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group7/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A person in a jacket, facing away from the camera, is walking along a countryside road
                        heading into the distance.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group8/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group8/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group8/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group8/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A man and other man are standing together in the middle of a tennis court, and speaking to the camera.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group9/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group9/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group9/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group9/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A thick blanket of snow covers the ground, where an elderly man  walks in front of the house.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group10/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group10/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group10/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group10/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A person in a jacket riding a horse, is walking along the countryside road.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group11/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group11/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group11/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group11/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A cat eating food out of a bowl while looking around, then the camera moves away to a
                        scene where another cat eats food.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group12/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group12/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group12/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group12/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        On a stage, a woman is rotating and waving her arms to show her belly dance.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group13/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group13/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group13/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group13/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A band composed of a group of young people is performing live music.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group14/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group14/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group14/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group14/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A horse in a blue cover walks at a fast pace, and then begins to slow down, taking a walk in the paddock.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group15/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group15/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group15/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group15/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                       Two women sit on a park bench, reading books while chatting to each other.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group16/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group16/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group16/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group16/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A woman hikes up the green mountain reaches the summit, and takes photos of the breathtaking view.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group17/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group17/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group17/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group17/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A girl is playing on a swing in the park.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group18/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group18/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group18/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group18/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A group of boys are playing football on the green field, with one passing the ball over another.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group19/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group19/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group19/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group19/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A woman in a raincoat holding an umbrella steps into the pouring rain, and tries to pass through the traffic.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group20/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group20/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group20/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group20/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        Two girls are holding hands together and joyfully going down the mountain.
                    </figcaption>
                </figure>
                <figure>
                    <img src="./static/images/low/group21/cogvideo.gif" alt="Teaser" style="width:24%; float:left;">
                    <img class="my-margin" src="./static/images/low/group21/vdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group21/lvdm.gif" alt="Teaser">
                    <img class="my-margin" src="./static/images/low/group21/ours.gif" alt="Teaser">
                    <figcaption style="margin-bottom:15pt">
                        A boy is riding a skateboard on the city street, and then falling down.
                    </figcaption>
                </figure>
                <!--        <div class="content has-text-justified">-->

                <br/>

            </div>
        </div>


        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Related Links</h2>

                <div class="content has-text-justified">
                    <p>
                        You may refer to previous works such as
                        <a href="https://github.com/THUDM/CogVideo">CogVideo</a>,
                        <a href="https://github.com/lucidrains/video-diffusion-pytorch">VDM</a>,
                        <a href="https://github.com/YingqingHe/LVDM">LVDM</a>,
                        <a href="https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion/text2img">Stable
                        Diffusion</a>,
                        and <a href="https://platform.openai.com/docs/models/gpt-3-5">GPT3.5</a>, which
                        serve as foundational frameworks for our Dysen-VDM framework and code repository.
                    </p>
                </div>
            </div>
        </div>

    </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>
      @articles{fei2023dysen,
          title = {Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models},
          author = {Hao Fei, Shengqiong Wu, Wei Ji, Hanwang Zhang, Tat-Seng Chua},
          journal = {CoRR},
          volume = {abs/2303.09508},
          year = {2023}
      }
</code></pre>
    </div>
</section>


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p style="text-align: center;">
                        The webpage is built based on <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
